{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxS1_SD4eiYW",
        "outputId": "9803a182-ea80-4d02-9cdb-ddeff4d3b9f2"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import gc\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import lightning.pytorch as pl\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3D-WVgy7fuVo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CUDA = True\n",
        "DEVICE = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
        "BATCH_SIZE = 4\n",
        "X_DIM = 1024\n",
        "EMBED_DIM = 768\n",
        "HIDDEN_DIM = 1024\n",
        "VOCAB_SIZE = 560\n",
        "LATENT_DIM = HIDDEN_DIM//4\n",
        "COMPUTE_LOGITS = False\n",
        "DROPOUT = 0.2\n",
        "LR = 1e-5\n",
        "EPOCHS = 3000\n",
        "EPOCH_BEGIN = 0\n",
        "\n",
        "PARAMS = {\n",
        "    'batch': BATCH_SIZE,\n",
        "    'x_dim': X_DIM,\n",
        "    'embed_dim': EMBED_DIM,\n",
        "    'hidden_dim': HIDDEN_DIM,\n",
        "    'vocab_size': VOCAB_SIZE,\n",
        "    'latent_dim': LATENT_DIM,\n",
        "    'dropout': DROPOUT,\n",
        "    'lr': LR\n",
        "}\n",
        "\n",
        "DEVICE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "82pwooWKjw77"
      },
      "outputs": [],
      "source": [
        "from torch import optim, Tensor\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_dims: List = [HIDDEN_DIM], latent_dim=64):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        modules = []\n",
        "\n",
        "        modules.append(\n",
        "            nn.Linear(EMBED_DIM, hidden_dims[0], bias=False)\n",
        "        )\n",
        "\n",
        "        for i in range(0, len(hidden_dims)):\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(\n",
        "                        hidden_dims[i] if i == 0 else hidden_dims[i-1]//2,\n",
        "                        hidden_dims[i]//2,\n",
        "                        bias=False\n",
        "                    ),\n",
        "                    nn.Dropout(DROPOUT/(i+1))\n",
        "                ),\n",
        "            )\n",
        "\n",
        "        self.module = nn.Sequential(*modules, nn.LeakyReLU(0.2))\n",
        "        self.fc_mean = nn.Linear(hidden_dims[-1]//2, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dims[-1]//2, latent_dim)\n",
        "\n",
        "    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n",
        "        hidden = self.module(input)\n",
        "        mean = self.fc_mean(hidden)\n",
        "        logvar = self.fc_logvar(hidden)\n",
        "\n",
        "        return hidden, mean, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dims: List = [HIDDEN_DIM], latent_dim=64):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        modules = []\n",
        "\n",
        "        hidden_dims.reverse()\n",
        "\n",
        "        modules.append(\n",
        "            nn.Linear(latent_dim, hidden_dims[0]//2, bias=False)\n",
        "        )\n",
        "\n",
        "        for i in range(0, len(hidden_dims)):\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(\n",
        "                        hidden_dims[i]//2 if i == 0 else hidden_dims[i-1],\n",
        "                        hidden_dims[i],\n",
        "                        bias=False\n",
        "                    ),\n",
        "                    nn.Dropout((DROPOUT/len(hidden_dims))*(i+1))\n",
        "                )\n",
        "            )\n",
        "\n",
        "        modules.append(\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.module = nn.Sequential(\n",
        "            *modules,\n",
        "            nn.Linear(hidden_dims[-1], EMBED_DIM, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n",
        "        result = self.module(input)\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "class VAE(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 latent_dim: int,\n",
        "                 hidden_dims: List = [HIDDEN_DIM]\n",
        "                 ) -> None:\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.emb = nn.Embedding(VOCAB_SIZE, EMBED_DIM, padding_idx=0)\n",
        "        self.encoder = Encoder(hidden_dims, latent_dim)\n",
        "        self.decoder = Decoder(hidden_dims, latent_dim)\n",
        "        self.z_emb = nn.Linear(latent_dim, EMBED_DIM, bias=False)\n",
        "        self.proj = nn.Linear(EMBED_DIM, VOCAB_SIZE, bias=True)\n",
        "        self.ln_out = nn.LayerNorm(VOCAB_SIZE)\n",
        "\n",
        "        self.emb.weight.data.uniform_(-0.1, 0.1)\n",
        "        self.proj.bias.data.zero_()\n",
        "        self.proj.weight.data.uniform_(-0.1, 0.1)\n",
        "\n",
        "    def encode(self, input: Tensor) -> List[Tensor]:\n",
        "        emb = self.emb(input)\n",
        "        hidden, mean, logvar = self.encoder(emb)\n",
        "\n",
        "        return [emb, hidden, mean, logvar]\n",
        "\n",
        "    def decode(self, z: Tensor) -> Tensor:\n",
        "        result = self.decoder(z) + self.z_emb(z)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def reparameterize(self, mean: Tensor, logvar: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Reparameterization trick to sample from N(mean, var) from\n",
        "        N(0,1).\n",
        "        :param mean: (Tensor) Mean of the latent Gaussian [B x D]\n",
        "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
        "        :return: (Tensor) [B x D]\n",
        "        \"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "\n",
        "        return eps * std + mean\n",
        "\n",
        "    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n",
        "        emb, hidden, mean, log_var = self.encode(input)\n",
        "        z = self.reparameterize(mean, log_var)\n",
        "        emb_hat = self.decode(z)\n",
        "        output = self.proj(emb_hat)\n",
        "        output = self.ln_out(output)\n",
        "        output = torch.softmax(output, dim=-1)\n",
        "\n",
        "        return [output, emb_hat, emb, hidden, mean, log_var]\n",
        "\n",
        "    def kl_loss(self, mean: Tensor, logvar: Tensor) -> Tensor:\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
        "\n",
        "        return kl_loss\n",
        "\n",
        "    def reconstruction_loss(self, input_emb: Tensor, output_emb: Tensor, input: Tensor, output: Tensor, padding_index=0) -> Tensor:\n",
        "        loss_emb = F.mse_loss(output_emb, input_emb)\n",
        "\n",
        "        if not COMPUTE_LOGITS:\n",
        "            return loss_emb\n",
        "\n",
        "        output = torch.argmax(output, dim=1)\n",
        "\n",
        "        # Create a mask to exclude the padding_idx from loss computation\n",
        "        mask = input != padding_index\n",
        "\n",
        "        # Apply the mask to the input and output tensors\n",
        "        input_masked = input.to(dtype=torch.float).view(-1)[mask.view(-1)]\n",
        "        output_masked = output.to(\n",
        "            dtype=torch.float).view(-1)[mask.view(-1)]\n",
        "\n",
        "        # Compute the cross-entropy loss only for non-padding positions\n",
        "        loss = F.cross_entropy(output_masked, input_masked)\n",
        "\n",
        "        recon_loss = loss_emb + loss\n",
        "\n",
        "        return recon_loss\n",
        "\n",
        "    def loss_function(self, input_emb: Tensor, output_emb: Tensor, input: Tensor, output: Tensor, mean: Tensor, logvar: Tensor, padding_index=0) -> Tensor:\n",
        "        recon_loss = self.reconstruction_loss(\n",
        "            input_emb, output_emb, input, output, padding_index)\n",
        "        kl_loss = self.kl_loss(mean, logvar)\n",
        "        total_loss = recon_loss + kl_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    def sample(self,\n",
        "               num_samples: int,\n",
        "               current_device: int, **kwargs) -> Tensor:\n",
        "        \"\"\"\n",
        "        Samples from the latent space.\n",
        "        :param num_samples: (Int) Number of samples\n",
        "        :param current_device: (Int) Device to run the model\n",
        "        :return: (Tensor)\n",
        "        \"\"\"\n",
        "        z = torch.randn(num_samples, self.latent_dim)\n",
        "        z = z.to(current_device)\n",
        "        samples = self.decode(z)\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input = batch[0][np.random.randint(0, len(batch[0]))]\n",
        "        output, emb_hat, emb, hidden, mean, log_var = self(input)\n",
        "        loss = self.loss_function(\n",
        "            emb,\n",
        "            emb_hat,\n",
        "            input,\n",
        "            output,\n",
        "            mean, log_var, padding_index=0\n",
        "        )\n",
        "\n",
        "        self.log('train_loss', loss, prog_bar=True, on_step=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=LR, betas=(0.5, 0.999))\n",
        "        self.trainer._scheduler = optim.lr_scheduler.StepLR(\n",
        "            optimizer, step_size=1, gamma=0.7)\n",
        "\n",
        "        return [optimizer], [self.trainer._scheduler]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sxu27xel11f",
        "outputId": "5233bc52-56e0-43af-83ac-03b3ddf5d4c5"
      },
      "outputs": [],
      "source": [
        "model = VAE(LATENT_DIM, hidden_dims=[\n",
        "            HIDDEN_DIM*4, HIDDEN_DIM*2, HIDDEN_DIM, HIDDEN_DIM//2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCH_BEGIN = 15\n",
        "\n",
        "load_dict = torch.load(f'embvae-{VOCAB_SIZE}x{EMBED_DIM}x{HIDDEN_DIM}-{EPOCH_BEGIN}.pth', map_location=DEVICE)\n",
        "load_keys = load_dict.keys()\n",
        "\n",
        "for k in model.state_dict():\n",
        "    if k not in load_keys:\n",
        "        load_dict[k] = model.state_dict()[k]\n",
        "\n",
        "model.load_state_dict(load_dict, strict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VAE(\n",
              "  (emb): Embedding(560, 768, padding_idx=0)\n",
              "  (encoder): Encoder(\n",
              "    (module): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=4096, bias=False)\n",
              "      (1): Sequential(\n",
              "        (0): Linear(in_features=4096, out_features=2048, bias=False)\n",
              "        (1): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "        (1): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Linear(in_features=1024, out_features=512, bias=False)\n",
              "        (1): Dropout(p=0.06666666666666667, inplace=False)\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): Linear(in_features=512, out_features=256, bias=False)\n",
              "        (1): Dropout(p=0.05, inplace=False)\n",
              "      )\n",
              "      (5): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (fc_mean): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (fc_logvar): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (module): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=256, bias=False)\n",
              "      (1): Sequential(\n",
              "        (0): Linear(in_features=256, out_features=512, bias=False)\n",
              "        (1): Dropout(p=0.05, inplace=False)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "        (1): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Linear(in_features=1024, out_features=2048, bias=False)\n",
              "        (1): Dropout(p=0.15000000000000002, inplace=False)\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): Linear(in_features=2048, out_features=4096, bias=False)\n",
              "        (1): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (5): LeakyReLU(negative_slope=0.2)\n",
              "      (6): Linear(in_features=4096, out_features=768, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (z_emb): Linear(in_features=256, out_features=768, bias=False)\n",
              "  (proj): Linear(in_features=768, out_features=560, bias=True)\n",
              "  (ln_out): LayerNorm((560,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ruP-E5pJYciP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([33999, 1024])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import json\n",
        "\n",
        "paths = list(\n",
        "    Path('/home/nico/data/ai/models/midi/all/').glob('a*_mid.json'))\n",
        "paths += list(\n",
        "    Path('/home/nico/data/ai/models/midi/all/').glob('b*_mid.json'))\n",
        "paths += list(\n",
        "    Path('/home/nico/data/ai/models/midi/all/').glob('c*_mid.json'))\n",
        "\n",
        "tokens = []\n",
        "\n",
        "for path in paths:\n",
        "  tokens += json.load(open(path))['ids']\n",
        "\n",
        "ids = torch.LongTensor(tokens)\n",
        "ids = torch.split(ids, X_DIM)\n",
        "ids = pad_sequence(ids, batch_first=True)\n",
        "dataset = TensorDataset(ids)\n",
        "data_loader = DataLoader(dataset, pin_memory=True, batch_size=BATCH_SIZE)\n",
        "\n",
        "ids.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightning.pytorch.callbacks import Callback\n",
        "import datetime\n",
        "\n",
        "EPOCHS_SAVE = 1\n",
        "\n",
        "\n",
        "class TrainCallback(Callback):\n",
        "    def on_train_epoch_start(self, trainer, pl_module):\n",
        "        if trainer.is_global_zero:\n",
        "            if trainer.global_step == 0:\n",
        "                timestamp = datetime.datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "                log = open('./embvae-train_log.txt', 'a')\n",
        "\n",
        "                log.write(f'NEW RUN {timestamp}\\n{PARAMS}\\n')\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        if trainer.is_global_zero:  # logging & save state_dict\n",
        "            if (trainer.current_epoch % EPOCHS_SAVE == 0):\n",
        "                to_save_dict = pl_module.state_dict()\n",
        "\n",
        "                try:\n",
        "                    torch.save(\n",
        "                        to_save_dict,\n",
        "                        f'./embvae-{VOCAB_SIZE}x{EMBED_DIM}x{HIDDEN_DIM}-{EPOCH_BEGIN + 1 + trainer.current_epoch}.pth',\n",
        "                    )\n",
        "                except Exception as error:\n",
        "                    print(error)\n",
        "\n",
        "    def on_train_batch_start(self, trainer, pl_module, batch, batch_idx):\n",
        "        if trainer.is_global_zero:\n",
        "            param_groups = trainer.optimizers[0].param_groups\n",
        "            lr = param_groups[-1]['lr']\n",
        "\n",
        "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
        "        if trainer.is_global_zero:\n",
        "            param_groups = trainer.optimizers[0].param_groups\n",
        "            lr = param_groups[-1]['lr']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36ec6daaa9c84ec4bce791c5ca7b693a",
            "4be857ccf05f4bb9b92e3a6deef704e7",
            "0fc69e9cd36d4ed5aef27c39c5e5cc3b",
            "c3c448f7c4f6444e98cfc60c24a373a9",
            "3b08fc4c6c9c48d8b942141e833c4b6f",
            "4af022d65a5b405899de554a8b0e6ce8",
            "5ec108775f6f4b789391a38e9bd59c89",
            "9de3008bfabc446c8575676e0cb71323",
            "25b9fea67d674935bbf2242be51762f2",
            "15f0b06678c347bdbb41f9f78f2d41c9",
            "2c15079f5c864eef9d305a146a4edb05"
          ]
        },
        "id": "6eqKDfhkM_9-",
        "outputId": "e5155dc8-bd69-478f-b6d7-77df55b651e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/home/nico/anaconda3/envs/midigpt/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "  warning_cache.warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name    | Type      | Params\n",
            "--------------------------------------\n",
            "0 | emb     | Embedding | 430 K \n",
            "1 | encoder | Encoder   | 14.4 M\n",
            "2 | decoder | Decoder   | 14.4 M\n",
            "3 | z_emb   | Linear    | 196 K \n",
            "4 | proj    | Linear    | 430 K \n",
            "5 | ln_out  | LayerNorm | 1.1 K \n",
            "--------------------------------------\n",
            "29.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "29.8 M    Total params\n",
            "119.317   Total estimated model params size (MB)\n",
            "/home/nico/anaconda3/envs/midigpt/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "546ae0e2267e44668e4f924b327496d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = pl.Trainer(\n",
        "    devices='auto',\n",
        "    max_epochs=100000,\n",
        "    accelerator=\"auto\",\n",
        "    log_every_n_steps=100,\n",
        "    callbacks=[\n",
        "        TrainCallback()\n",
        "    ],\n",
        "    enable_checkpointing=False\n",
        ")\n",
        "trainer.fit(model=model, train_dataloaders=data_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "sample = dataset[np.random.randint(0, len(dataset)-1)][0]\n",
        "\n",
        "with torch.no_grad():\n",
        "    output, emb_hat, emb, hidden, mean, log_var = model(sample.to(DEVICE))\n",
        "\n",
        "emb_hat, emb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "324c59c51086f4574d8cdca1e3c0b1230dd2abd272c806cb05bd1db673024182"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fc69e9cd36d4ed5aef27c39c5e5cc3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9de3008bfabc446c8575676e0cb71323",
            "max": 54,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25b9fea67d674935bbf2242be51762f2",
            "value": 0
          }
        },
        "15f0b06678c347bdbb41f9f78f2d41c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b9fea67d674935bbf2242be51762f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c15079f5c864eef9d305a146a4edb05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36ec6daaa9c84ec4bce791c5ca7b693a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4be857ccf05f4bb9b92e3a6deef704e7",
              "IPY_MODEL_0fc69e9cd36d4ed5aef27c39c5e5cc3b",
              "IPY_MODEL_c3c448f7c4f6444e98cfc60c24a373a9"
            ],
            "layout": "IPY_MODEL_3b08fc4c6c9c48d8b942141e833c4b6f"
          }
        },
        "3b08fc4c6c9c48d8b942141e833c4b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4af022d65a5b405899de554a8b0e6ce8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be857ccf05f4bb9b92e3a6deef704e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af022d65a5b405899de554a8b0e6ce8",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec108775f6f4b789391a38e9bd59c89",
            "value": "Epoch 0:   0%"
          }
        },
        "5ec108775f6f4b789391a38e9bd59c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9de3008bfabc446c8575676e0cb71323": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c448f7c4f6444e98cfc60c24a373a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f0b06678c347bdbb41f9f78f2d41c9",
            "placeholder": "​",
            "style": "IPY_MODEL_2c15079f5c864eef9d305a146a4edb05",
            "value": " 0/54 [00:00&lt;?, ?it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
