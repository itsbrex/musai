{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "from miditok import REMIPlus, MMM\n",
    "from miditok.constants import ADDITIONAL_TOKENS\n",
    "from torch.nn import functional as F\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "CTX_LEN = 512\n",
    "PRECISION = 'bf16'\n",
    "\n",
    "os.environ['RWKV_T_MAX'] = str(CTX_LEN)\n",
    "os.environ['RWKV_FLOAT_MODE'] = PRECISION\n",
    "\n",
    "sys.path.append('./src/model')\n",
    "sys.path.append('./src/tools')\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runner import RWKV_RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_NAME = 'sequences'\n",
    "IS_BPE = True\n",
    "TOKENS_PATH = f\"/home/nico/data/ai/models/midi/{PROJ_NAME}{'/bpe' if IS_BPE else ''}\"\n",
    "\n",
    "Path(f'./out/{PROJ_NAME}').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BINS_VELOCITY = (24)\n",
    "BINS_TEMPO = (24)\n",
    "\n",
    "additional_tokens = ADDITIONAL_TOKENS\n",
    "additional_tokens['Chord'] = True\n",
    "additional_tokens['TimeSignature'] = True\n",
    "additional_tokens['Program'] = True\n",
    "additional_tokens['nb_tempos'] = BINS_TEMPO\n",
    "TOKENIZER = MMM(\n",
    "    additional_tokens=additional_tokens, \n",
    "    params=f'{TOKENS_PATH}/token_params.cfg',\n",
    "    nb_velocities=BINS_VELOCITY\n",
    ")\n",
    "\n",
    "ORIG_VOCAB_SIZE = len(TOKENIZER.vocab)\n",
    "BPE_VOCAB_SIZE = int(ORIG_VOCAB_SIZE * 1.25)\n",
    "\n",
    "(ORIG_VOCAB_SIZE, BPE_VOCAB_SIZE, len(TOKENIZER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EMBED = 768\n",
    "N_LAYER = 10\n",
    "CTX_LEN = 512\n",
    "\n",
    "params = {\n",
    "    'ctx_len': CTX_LEN,\n",
    "    'n_embd': N_EMBED,\n",
    "    'n_layer': N_LAYER,\n",
    "}\n",
    "\n",
    "params_obj = namedtuple('RWKVParams', params.keys())(*params.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MAX_ITER = 1024*3\n",
    "\n",
    "# this is where we introduce some randomness\n",
    "NOISE_LEVEL = 0.55\n",
    "NOISE_FREQ = 10\n",
    "PHASE = 0\n",
    "\n",
    "\n",
    "def gen_sin_wave(total_iterations, min_value, max_value, noise_scale, noise_frequency, main_phase):\n",
    "    \"\"\"\n",
    "    Generate a sinusoidal wave with optional noise.\n",
    "\n",
    "    Args:\n",
    "        total_iterations (int): The total number of iterations.\n",
    "        min_value (float): The minimum value of the wave.\n",
    "        max_value (float): The maximum value of the wave.\n",
    "        noise_scale (float): The scale factor for the noise.\n",
    "        noise_frequency (float): The frequency of the noise wave.\n",
    "        main_phase (float): The phase of the main wave.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of generated wave values.\n",
    "\n",
    "    \"\"\"\n",
    "    progress = np.linspace(0, 1, total_iterations)\n",
    "    main_wave = np.sin(2 * np.pi * progress + main_phase)\n",
    "    noise_wave = np.sin(2 * np.pi * noise_frequency * progress - main_phase / 2)\n",
    "    noise = noise_scale * noise_wave\n",
    "    values = min_value + (max_value - min_value) * \\\n",
    "        (1 + main_wave) / 2 + noise\n",
    "\n",
    "    np.clip(values, min_value, max_value, out=values)\n",
    "\n",
    "    return values.tolist()\n",
    "\n",
    "\n",
    "temp_values = gen_sin_wave(MAX_ITER, 0.25, 0.85, NOISE_LEVEL, NOISE_FREQ, PHASE)\n",
    "top_p_values = gen_sin_wave(MAX_ITER, 0.75, 1.0, NOISE_LEVEL, NOISE_FREQ*2, PHASE+6)\n",
    "\n",
    "plt.plot(temp_values)\n",
    "plt.plot(top_p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "SEED = random.randint(1000, 10000)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "args = types.SimpleNamespace()\n",
    "args.RUN_DEVICE = \"cuda\"\n",
    "args.FLOAT_MODE = PRECISION\n",
    "args.map_location = 'cpu'\n",
    "args.base_model = f'/home/nico/dev/projects/ai/musai/out/{PROJ_NAME}/rwkv-40'\n",
    "args.n_layer = params['n_layer']\n",
    "args.n_embd = params['n_embd']\n",
    "args.ctx_len = int(params['ctx_len'])\n",
    "\n",
    "model_rnn = RWKV_RNN(args)\n",
    "model_rnn.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from miditoolkit import MidiFile\n",
    "\n",
    "init_state = None\n",
    "out_tokens = []\n",
    "tokens_file_paths = list(Path(TOKENS_PATH).glob('*.json'))\n",
    "\n",
    "random.shuffle(tokens_file_paths)\n",
    "\n",
    "SAMPLE_TOKENS_FILE = '/home/nico/data/ai/models/midi/sequences/bpe/133_beethoven_sonate_op2_scherzo_mid.json'\n",
    "\n",
    "# token_ids = json.load(open(tokens_file_paths[0]))['ids']\n",
    "token_ids = json.load(open(SAMPLE_TOKENS_FILE))['ids']\n",
    "# sample = TOKENIZER.midi_to_tokens(MidiFile('examples/2023-06-11T12-59-05-739764.mid'))\n",
    "# token_ids = sample.ids\n",
    "max_seq = 256\n",
    "init_tokens = token_ids[:max_seq]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from runner import sample_logits, repetition_penalty\n",
    "\n",
    "d = datetime.datetime.now().isoformat()\n",
    "d = re.sub(r'[^\\dT]{1,}', '-', d)\n",
    "\n",
    "for x in range(len(init_tokens)):\n",
    "    init_out, init_state = model_rnn.forward([init_tokens[x]], init_state)\n",
    "\n",
    "    # ignore padding\n",
    "    init_out[0] = -float('inf')\n",
    "\n",
    "    out_token = sample_logits(init_out.detach(), temperature=0.15)\n",
    "\n",
    "    out_tokens.append(out_token)\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    out, init_state = model_rnn.forward(out_tokens, init_state)\n",
    "\n",
    "    # ignore padding\n",
    "    out[0] = -float('inf')\n",
    "\n",
    "    # apply repetition penalty\n",
    "    out = repetition_penalty(out, out_tokens, [\n",
    "                             4, 5, 6, 7], repetition_penalty=1.25, seq_len=128, decay_factor=0.8)\n",
    "\n",
    "    out_token = sample_logits(\n",
    "        out.detach(), temperature=temp_values[i], top_p=top_p_values[i])\n",
    "\n",
    "    out_tokens.append(out_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import parse_bpe_tokens\n",
    "\n",
    "seqin = parse_bpe_tokens(TOKENIZER, token_ids)\n",
    "seqout = parse_bpe_tokens(TOKENIZER, out_tokens)\n",
    "tailhead_len = max_seq\n",
    "\n",
    "set(seqin[:tailhead_len]) - set(seqout[:tailhead_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(seqin[:tailhead_len] + ['...'] + seqin[len(seqin)-tailhead_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(seqout[:tailhead_len] + ['...'] + seqout[len(seqout)-tailhead_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'out/{PROJ_NAME}/{d}.mid'\n",
    "fname_orig = f'out/{PROJ_NAME}/{d}_orig.mid'\n",
    "\n",
    "TOKENIZER(out_tokens).dump(fname)\n",
    "TOKENIZER(token_ids).dump(fname_orig)\n",
    "\n",
    "[fname, fname_orig]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "324c59c51086f4574d8cdca1e3c0b1230dd2abd272c806cb05bd1db673024182"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
