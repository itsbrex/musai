{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -q -U bitsandbytes\n%pip install -q -U git+https://github.com/huggingface/transformers.git\n%pip install -q -U git+https://github.com/huggingface/peft.git\n%pip install -q -U git+https://github.com/huggingface/accelerate.git\n%pip install -q -U gdown\n%pip install -q -U deepspeed==0.9.2\n%pip install -q -U pytorch_lightning==1.8.6","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-23T01:17:29.273973Z","iopub.execute_input":"2023-06-23T01:17:29.274362Z","iopub.status.idle":"2023-06-23T01:20:15.611302Z","shell.execute_reply.started":"2023-06-23T01:17:29.274332Z","shell.execute_reply":"2023-06-23T01:20:15.609941Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nprint(\"Pytorch version：\")\nprint(torch.__version__)\nprint(\"CUDA Version: \")\nprint(torch.version.cuda)\nprint(\"cuDNN version is :\")\nprint(torch.backends.cudnn.version())","metadata":{"execution":{"iopub.status.busy":"2023-06-23T01:27:28.463956Z","iopub.execute_input":"2023-06-23T01:27:28.464988Z","iopub.status.idle":"2023-06-23T01:27:30.151613Z","shell.execute_reply.started":"2023-06-23T01:27:28.464936Z","shell.execute_reply":"2023-06-23T01:27:30.150658Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Pytorch version：\n2.0.0\nCUDA Version: \n11.8\ncuDNN version is :\n8700\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://huggingface.co/BlinkDL/rwkv-4-world/resolve/main/RWKV-4-World-0.4B-v1-20230529-ctx4096.pth","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/Blealtan/RWKV-LM-LoRA.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown -O colab --folder https://drive.google.com/drive/folders/1FYLc9dX_K2xh_gcm92QtekVDKLw8zGqJ?usp=sharing","metadata":{"execution":{"iopub.status.busy":"2023-06-23T01:27:39.097475Z","iopub.execute_input":"2023-06-23T01:27:39.098186Z","iopub.status.idle":"2023-06-23T01:29:13.793151Z","shell.execute_reply.started":"2023-06-23T01:27:39.098142Z","shell.execute_reply":"2023-06-23T01:29:13.791774Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Retrieving folder list\nProcessing file 14lWIG8tdmOQ5cB2g9fqa43b1ACSGFXk- bpe.tgz\nRetrieving folder 1aD-x4gjChyzyWbjEPbnu1pWhp4BofgXs cuda\nProcessing file 1ForvHKlYTa7FFIAWrPYA4RLMzCpeFVb9 wkv_cuda_bf16.cu\nProcessing file 1o1UsfSum6dOMUhfhcUAJuZrIeug-8k3L wkv_cuda.cu\nProcessing file 15waWBOsmMK1YZkjIxlR9dC6UfcOjGOez wkv_op_bf16.cpp\nProcessing file 16QW5sJGUW0pnsQ6w5_H85Oz9gq6os3Dj wkv_op.cpp\nRetrieving folder 1WgmeumjZ6uaFWRaLLUqK4lYHUh6aagxI examples\nProcessing file 1gsU0O6daM4Xu1fBLYL2QQ0XBxoTMSS3M 2023-06-11T12-59-05-739764.mid\nProcessing file 1DQ30CfdKGibZRTaoSieUGts4Hqbq0zsg 2023-06-11T12-59-05-739764.mp3\nProcessing file 1Zz_r5tLyeCY0JMjIL-Jorz0AcZeQMl-k 2023-06-11T13-28-38-899081.mid\nProcessing file 1Teq52yzNhAu8YdNJk1b1YAQLgbXxOVNL 2023-06-11T13-28-38-899081.mp3\nProcessing file 1H1PedrwqJ9wBYX-V3PtkYTHMkevbFiWC 2023-06-12T14-41-12-895476.mp3\nProcessing file 1Y_4k5VuszrWZA9fcfdeEA6cBJBn_MJpY news.ar_text_document.bin\nProcessing file 1HpKuTwazAndj9Kc_oLm3RtLYhHsgjMle news.ar_text_document.idx\nRetrieving folder 1uxd02x_j_RMs_pMml4aSfrz1dEzCtCM1 python\nProcessing file 1UwHvmcFoSeMYBOWE5isF3iYxVy0ELjNI binidx.py\nProcessing file 14OJx99v85e-tImNyQQVP6ncvcsMqwTs8 model_run.py\nProcessing file 1rfJLQuFrtxbcG-FEkFI6slTOtbK5EDFG model.py\nProcessing file 1b5zDpKI0BEcM_ikn95bFP-C9sF0kVyaS trainer.py\nProcessing file 1gX65jUeTW1KlcJML1Kx6wXEv1nQ3U7RC utils.py\nProcessing file 11-_4SthbM4g2kjV7uLggz7AsT6m1F-vG rwkv_vocab_v20230424.txt\nProcessing file 10K8j6wIMfp3By0wTuGmH0-lbgy8f3OTr sample_text_document.bin\nProcessing file 1OEJT3Ou1XdpSHDpFTqARknTpvBarA5ki sample_text_document.idx\nProcessing file 16iwz0rayZECzPkCSGw8k_Fl1hI3IRvkP token_params.cfg\nRetrieving folder list completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=14lWIG8tdmOQ5cB2g9fqa43b1ACSGFXk-\nTo: /kaggle/working/colab/bpe.tgz\n100%|███████████████████████████████████████| 22.8M/22.8M [00:00<00:00, 170MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1ForvHKlYTa7FFIAWrPYA4RLMzCpeFVb9\nTo: /kaggle/working/colab/cuda/wkv_cuda_bf16.cu\n100%|██████████████████████████████████████| 4.90k/4.90k [00:00<00:00, 21.8MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1o1UsfSum6dOMUhfhcUAJuZrIeug-8k3L\nTo: /kaggle/working/colab/cuda/wkv_cuda.cu\n100%|██████████████████████████████████████| 4.60k/4.60k [00:00<00:00, 17.0MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=15waWBOsmMK1YZkjIxlR9dC6UfcOjGOez\nTo: /kaggle/working/colab/cuda/wkv_op_bf16.cpp\n100%|██████████████████████████████████████| 1.29k/1.29k [00:00<00:00, 7.32MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=16QW5sJGUW0pnsQ6w5_H85Oz9gq6os3Dj\nTo: /kaggle/working/colab/cuda/wkv_op.cpp\n100%|██████████████████████████████████████| 1.25k/1.25k [00:00<00:00, 3.88MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1gsU0O6daM4Xu1fBLYL2QQ0XBxoTMSS3M\nTo: /kaggle/working/colab/examples/2023-06-11T12-59-05-739764.mid\n100%|██████████████████████████████████████| 12.3k/12.3k [00:00<00:00, 42.9MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1DQ30CfdKGibZRTaoSieUGts4Hqbq0zsg\nTo: /kaggle/working/colab/examples/2023-06-11T12-59-05-739764.mp3\n100%|███████████████████████████████████████| 6.08M/6.08M [00:00<00:00, 127MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1Zz_r5tLyeCY0JMjIL-Jorz0AcZeQMl-k\nTo: /kaggle/working/colab/examples/2023-06-11T13-28-38-899081.mid\n100%|██████████████████████████████████████| 7.57k/7.57k [00:00<00:00, 30.6MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1Teq52yzNhAu8YdNJk1b1YAQLgbXxOVNL\nTo: /kaggle/working/colab/examples/2023-06-11T13-28-38-899081.mp3\n100%|███████████████████████████████████████| 4.21M/4.21M [00:00<00:00, 121MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1H1PedrwqJ9wBYX-V3PtkYTHMkevbFiWC\nTo: /kaggle/working/colab/examples/2023-06-12T14-41-12-895476.mp3\n100%|███████████████████████████████████████| 1.22M/1.22M [00:00<00:00, 116MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1Y_4k5VuszrWZA9fcfdeEA6cBJBn_MJpY\nFrom (redirected): https://drive.google.com/uc?id=1Y_4k5VuszrWZA9fcfdeEA6cBJBn_MJpY&confirm=t&uuid=fc2a66df-b167-41a6-a2c8-34c7bc726ed7\nTo: /kaggle/working/colab/news.ar_text_document.bin\n100%|████████████████████████████████████████| 978M/978M [00:15<00:00, 62.2MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1HpKuTwazAndj9Kc_oLm3RtLYhHsgjMle\nTo: /kaggle/working/colab/news.ar_text_document.idx\n100%|███████████████████████████████████████| 10.7M/10.7M [00:00<00:00, 125MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1UwHvmcFoSeMYBOWE5isF3iYxVy0ELjNI\nFrom (redirected): https://drive.google.com/uc?id=1UwHvmcFoSeMYBOWE5isF3iYxVy0ELjNI&confirm=t&uuid=09390bfe-6ff2-40e3-98e0-160ef2aae391\nTo: /kaggle/working/colab/python/binidx.py\n100%|██████████████████████████████████████| 8.65k/8.65k [00:00<00:00, 24.4MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=14OJx99v85e-tImNyQQVP6ncvcsMqwTs8\nFrom (redirected): https://drive.google.com/uc?id=14OJx99v85e-tImNyQQVP6ncvcsMqwTs8&confirm=t&uuid=62eca969-d516-4fd0-a71c-e69479c1cdf7\nTo: /kaggle/working/colab/python/model_run.py\n100%|██████████████████████████████████████| 8.86k/8.86k [00:00<00:00, 29.2MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1rfJLQuFrtxbcG-FEkFI6slTOtbK5EDFG\nFrom (redirected): https://drive.google.com/uc?id=1rfJLQuFrtxbcG-FEkFI6slTOtbK5EDFG&confirm=t&uuid=1fa473db-fd1a-4909-bc4c-3375bc9cbd39\nTo: /kaggle/working/colab/python/model.py\n100%|██████████████████████████████████████| 29.6k/29.6k [00:00<00:00, 69.2MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1b5zDpKI0BEcM_ikn95bFP-C9sF0kVyaS\nFrom (redirected): https://drive.google.com/uc?id=1b5zDpKI0BEcM_ikn95bFP-C9sF0kVyaS&confirm=t&uuid=c7a0058b-ba5b-4e35-910c-1c1810e4f4a1\nTo: /kaggle/working/colab/python/trainer.py\n100%|██████████████████████████████████████| 7.04k/7.04k [00:00<00:00, 20.3MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1gX65jUeTW1KlcJML1Kx6wXEv1nQ3U7RC\nFrom (redirected): https://drive.google.com/uc?id=1gX65jUeTW1KlcJML1Kx6wXEv1nQ3U7RC&confirm=t&uuid=9edb1a1e-8e34-416e-bafe-feb222fd92f2\nTo: /kaggle/working/colab/python/utils.py\n100%|██████████████████████████████████████| 4.63k/4.63k [00:00<00:00, 19.6MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=11-_4SthbM4g2kjV7uLggz7AsT6m1F-vG\nTo: /kaggle/working/colab/rwkv_vocab_v20230424.txt\n100%|███████████████████████████████████████| 1.09M/1.09M [00:00<00:00, 102MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=10K8j6wIMfp3By0wTuGmH0-lbgy8f3OTr\nTo: /kaggle/working/colab/sample_text_document.bin\n100%|██████████████████████████████████████████| 640/640 [00:00<00:00, 3.68MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1OEJT3Ou1XdpSHDpFTqARknTpvBarA5ki\nTo: /kaggle/working/colab/sample_text_document.idx\n100%|██████████████████████████████████████████| 182/182 [00:00<00:00, 1.26MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=16iwz0rayZECzPkCSGw8k_Fl1hI3IRvkP\nTo: /kaggle/working/colab/token_params.cfg\n100%|██████████████████████████████████████| 45.9k/45.9k [00:00<00:00, 62.1MB/s]\nDownload completed\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/RWKV-LM-LoRA/RWKV-v4neo","metadata":{"execution":{"iopub.status.busy":"2023-06-23T01:29:20.831762Z","iopub.execute_input":"2023-06-23T01:29:20.832768Z","iopub.status.idle":"2023-06-23T01:29:20.842355Z","shell.execute_reply.started":"2023-06-23T01:29:20.832717Z","shell.execute_reply":"2023-06-23T01:29:20.841019Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/RWKV-LM-LoRA/RWKV-v4neo\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py \\\n  --load_model /kaggle/working/RWKV-4-World-0.4B-v1-20230529-ctx4096.pth \\\n  --proj_dir /kaggle/working \\\n  --data_file /kaggle/working/colab/news.ar_text_document \\\n  --data_type binidx \\\n  --vocab_size 65536 --ctx_len 4096 --epoch_steps 1000 --epoch_count 1000 --epoch_begin 0 --epoch_save 5 \\\n  --micro_bsz 2 --accumulate_grad_batches 2 \\\n  --n_layer 24 --n_embd 1024 --pre_ffn 0 --head_qk 0 --lr_init 1e-4 --lr_final 1e-4 --warmup_steps 0 \\\n  --beta1 0.9 --beta2 0.999 --adam_eps 1e-8 --accelerator gpu --devices 2 --precision bf16 \\\n  --strategy deepspeed_stage_2 --grad_cp 0 \\\n  --lora --lora_r 8 --lora_alpha 16 --lora_dropout 0.01 --lora_parts=att,ffn,time,ln","metadata":{"execution":{"iopub.status.busy":"2023-06-23T01:37:00.051748Z","iopub.execute_input":"2023-06-23T01:37:00.052818Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nRWKV_MY_TESTING \nUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\nDetected CUDA files, patching ldflags\nEmitting ninja build file /root/.cache/torch_extensions/py310_cu118/wkv_4096_bf16/build.ninja...\nBuilding extension module wkv_4096_bf16...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nninja: no work to do.\nLoading extension module wkv_4096_bf16...\n  LoRA additionally training module blocks.0.ln1\n  LoRA additionally training module blocks.0.ln2\n  LoRA additionally training module blocks.0.ln0\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.0.att.key\n  LoRA training module blocks.0.att.value\n  LoRA training module blocks.0.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.0.ffn.key\n  LoRA training module blocks.0.ffn.receptance\n  LoRA training module blocks.0.ffn.value\n  LoRA additionally training module blocks.1.ln1\n  LoRA additionally training module blocks.1.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.1.att.key\n  LoRA training module blocks.1.att.value\n  LoRA training module blocks.1.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.1.ffn.key\n  LoRA training module blocks.1.ffn.receptance\n  LoRA training module blocks.1.ffn.value\n  LoRA additionally training module blocks.2.ln1\n  LoRA additionally training module blocks.2.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.2.att.key\n  LoRA training module blocks.2.att.value\n  LoRA training module blocks.2.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.2.ffn.key\n  LoRA training module blocks.2.ffn.receptance\n  LoRA training module blocks.2.ffn.value\n  LoRA additionally training module blocks.3.ln1\n  LoRA additionally training module blocks.3.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.3.att.key\n  LoRA training module blocks.3.att.value\n  LoRA training module blocks.3.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.3.ffn.key\n  LoRA training module blocks.3.ffn.receptance\n  LoRA training module blocks.3.ffn.value\n  LoRA additionally training module blocks.4.ln1\n  LoRA additionally training module blocks.4.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.4.att.key\n  LoRA training module blocks.4.att.value\n  LoRA training module blocks.4.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.4.ffn.key\n  LoRA training module blocks.4.ffn.receptance\n  LoRA training module blocks.4.ffn.value\n  LoRA additionally training module blocks.5.ln1\n  LoRA additionally training module blocks.5.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.5.att.key\n  LoRA training module blocks.5.att.value\n  LoRA training module blocks.5.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.5.ffn.key\n  LoRA training module blocks.5.ffn.receptance\n  LoRA training module blocks.5.ffn.value\n  LoRA additionally training module blocks.6.ln1\n  LoRA additionally training module blocks.6.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.6.att.key\n  LoRA training module blocks.6.att.value\n  LoRA training module blocks.6.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.6.ffn.key\n  LoRA training module blocks.6.ffn.receptance\n  LoRA training module blocks.6.ffn.value\n  LoRA additionally training module blocks.7.ln1\n  LoRA additionally training module blocks.7.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.7.att.key\n  LoRA training module blocks.7.att.value\n  LoRA training module blocks.7.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.7.ffn.key\n  LoRA training module blocks.7.ffn.receptance\n  LoRA training module blocks.7.ffn.value\n  LoRA additionally training module blocks.8.ln1\n  LoRA additionally training module blocks.8.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.8.att.key\n  LoRA training module blocks.8.att.value\n  LoRA training module blocks.8.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.8.ffn.key\n  LoRA training module blocks.8.ffn.receptance\n  LoRA training module blocks.8.ffn.value\n  LoRA additionally training module blocks.9.ln1\n  LoRA additionally training module blocks.9.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.9.att.key\n  LoRA training module blocks.9.att.value\n  LoRA training module blocks.9.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.9.ffn.key\n  LoRA training module blocks.9.ffn.receptance\n  LoRA training module blocks.9.ffn.value\n  LoRA additionally training module blocks.10.ln1\n  LoRA additionally training module blocks.10.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.10.att.key\n  LoRA training module blocks.10.att.value\n  LoRA training module blocks.10.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.10.ffn.key\n  LoRA training module blocks.10.ffn.receptance\n  LoRA training module blocks.10.ffn.value\n  LoRA additionally training module blocks.11.ln1\n  LoRA additionally training module blocks.11.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.11.att.key\n  LoRA training module blocks.11.att.value\n  LoRA training module blocks.11.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.11.ffn.key\n  LoRA training module blocks.11.ffn.receptance\n  LoRA training module blocks.11.ffn.value\n  LoRA additionally training module blocks.12.ln1\n  LoRA additionally training module blocks.12.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.12.att.key\n  LoRA training module blocks.12.att.value\n  LoRA training module blocks.12.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.12.ffn.key\n  LoRA training module blocks.12.ffn.receptance\n  LoRA training module blocks.12.ffn.value\n  LoRA additionally training module blocks.13.ln1\n  LoRA additionally training module blocks.13.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.13.att.key\n  LoRA training module blocks.13.att.value\n  LoRA training module blocks.13.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.13.ffn.key\n  LoRA training module blocks.13.ffn.receptance\n  LoRA training module blocks.13.ffn.value\n  LoRA additionally training module blocks.14.ln1\n  LoRA additionally training module blocks.14.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.14.att.key\n  LoRA training module blocks.14.att.value\n  LoRA training module blocks.14.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.14.ffn.key\n  LoRA training module blocks.14.ffn.receptance\n  LoRA training module blocks.14.ffn.value\n  LoRA additionally training module blocks.15.ln1\n  LoRA additionally training module blocks.15.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.15.att.key\n  LoRA training module blocks.15.att.value\n  LoRA training module blocks.15.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.15.ffn.key\n  LoRA training module blocks.15.ffn.receptance\n  LoRA training module blocks.15.ffn.value\n  LoRA additionally training module blocks.16.ln1\n  LoRA additionally training module blocks.16.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.16.att.key\n  LoRA training module blocks.16.att.value\n  LoRA training module blocks.16.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.16.ffn.key\n  LoRA training module blocks.16.ffn.receptance\n  LoRA training module blocks.16.ffn.value\n  LoRA additionally training module blocks.17.ln1\n  LoRA additionally training module blocks.17.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.17.att.key\n  LoRA training module blocks.17.att.value\n  LoRA training module blocks.17.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.17.ffn.key\n  LoRA training module blocks.17.ffn.receptance\n  LoRA training module blocks.17.ffn.value\n  LoRA additionally training module blocks.18.ln1\n  LoRA additionally training module blocks.18.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.18.att.key\n  LoRA training module blocks.18.att.value\n  LoRA training module blocks.18.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.18.ffn.key\n  LoRA training module blocks.18.ffn.receptance\n  LoRA training module blocks.18.ffn.value\n  LoRA additionally training module blocks.19.ln1\n  LoRA additionally training module blocks.19.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.19.att.key\n  LoRA training module blocks.19.att.value\n  LoRA training module blocks.19.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.19.ffn.key\n  LoRA training module blocks.19.ffn.receptance\n  LoRA training module blocks.19.ffn.value\n  LoRA additionally training module blocks.20.ln1\n  LoRA additionally training module blocks.20.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.20.att.key\n  LoRA training module blocks.20.att.value\n  LoRA training module blocks.20.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.20.ffn.key\n  LoRA training module blocks.20.ffn.receptance\n  LoRA training module blocks.20.ffn.value\n  LoRA additionally training module blocks.21.ln1\n  LoRA additionally training module blocks.21.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.21.att.key\n  LoRA training module blocks.21.att.value\n  LoRA training module blocks.21.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.21.ffn.key\n  LoRA training module blocks.21.ffn.receptance\n  LoRA training module blocks.21.ffn.value\n  LoRA additionally training module blocks.22.ln1\n  LoRA additionally training module blocks.22.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.22.att.key\n  LoRA training module blocks.22.att.value\n  LoRA training module blocks.22.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.22.ffn.key\n  LoRA training module blocks.22.ffn.receptance\n  LoRA training module blocks.22.ffn.value\n  LoRA additionally training module blocks.23.ln1\n  LoRA additionally training module blocks.23.ln2\n  LoRA additionally training parameter time_decay\n  LoRA additionally training parameter time_first\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_v\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.23.att.key\n  LoRA training module blocks.23.att.value\n  LoRA training module blocks.23.att.receptance\n  LoRA additionally training parameter time_mix_k\n  LoRA additionally training parameter time_mix_r\n  LoRA training module blocks.23.ffn.key\n  LoRA training module blocks.23.ffn.receptance\n  LoRA training module blocks.23.ffn.value\n65536 1024  emb.weight\n1024        blocks.0.ln1.weight\n1024        blocks.0.ln1.bias\n1024        blocks.0.ln2.weight\n1024        blocks.0.ln2.bias\n1024        blocks.0.ln0.weight\n1024        blocks.0.ln0.bias\n1024        blocks.0.att.time_decay\n1024        blocks.0.att.time_first\n1024        blocks.0.att.time_mix_k\n1024        blocks.0.att.time_mix_v\n1024        blocks.0.att.time_mix_r\n1024  1024  blocks.0.att.key.weight\n8     1024  blocks.0.att.key.lora_A\n1024  8     blocks.0.att.key.lora_B\n1024  1024  blocks.0.att.value.weight\n8     1024  blocks.0.att.value.lora_A\n1024  8     blocks.0.att.value.lora_B\n1024  1024  blocks.0.att.receptance.weight\n8     1024  blocks.0.att.receptance.lora_A\n1024  8     blocks.0.att.receptance.lora_B\n1024  1024  blocks.0.att.output.weight\n1024        blocks.0.ffn.time_mix_k\n1024        blocks.0.ffn.time_mix_r\n4096  1024  blocks.0.ffn.key.weight\n8     1024  blocks.0.ffn.key.lora_A\n4096  8     blocks.0.ffn.key.lora_B\n1024  1024  blocks.0.ffn.receptance.weight\n8     1024  blocks.0.ffn.receptance.lora_A\n1024  8     blocks.0.ffn.receptance.lora_B\n1024  4096  blocks.0.ffn.value.weight\n8     4096  blocks.0.ffn.value.lora_A\n1024  8     blocks.0.ffn.value.lora_B\n1024        blocks.1.ln1.weight\n1024        blocks.1.ln1.bias\n1024        blocks.1.ln2.weight\n1024        blocks.1.ln2.bias\n1024        blocks.1.att.time_decay\n1024        blocks.1.att.time_first\n1024        blocks.1.att.time_mix_k\n1024        blocks.1.att.time_mix_v\n1024        blocks.1.att.time_mix_r\n1024  1024  blocks.1.att.key.weight\n8     1024  blocks.1.att.key.lora_A\n1024  8     blocks.1.att.key.lora_B\n1024  1024  blocks.1.att.value.weight\n8     1024  blocks.1.att.value.lora_A\n1024  8     blocks.1.att.value.lora_B\n1024  1024  blocks.1.att.receptance.weight\n8     1024  blocks.1.att.receptance.lora_A\n1024  8     blocks.1.att.receptance.lora_B\n1024  1024  blocks.1.att.output.weight\n1024        blocks.1.ffn.time_mix_k\n1024        blocks.1.ffn.time_mix_r\n4096  1024  blocks.1.ffn.key.weight\n8     1024  blocks.1.ffn.key.lora_A\n4096  8     blocks.1.ffn.key.lora_B\n1024  1024  blocks.1.ffn.receptance.weight\n8     1024  blocks.1.ffn.receptance.lora_A\n1024  8     blocks.1.ffn.receptance.lora_B\n1024  4096  blocks.1.ffn.value.weight\n8     4096  blocks.1.ffn.value.lora_A\n1024  8     blocks.1.ffn.value.lora_B\n1024        blocks.2.ln1.weight\n1024        blocks.2.ln1.bias\n1024        blocks.2.ln2.weight\n1024        blocks.2.ln2.bias\n1024        blocks.2.att.time_decay\n1024        blocks.2.att.time_first\n1024        blocks.2.att.time_mix_k\n1024        blocks.2.att.time_mix_v\n1024        blocks.2.att.time_mix_r\n1024  1024  blocks.2.att.key.weight\n8     1024  blocks.2.att.key.lora_A\n1024  8     blocks.2.att.key.lora_B\n1024  1024  blocks.2.att.value.weight\n8     1024  blocks.2.att.value.lora_A\n1024  8     blocks.2.att.value.lora_B\n1024  1024  blocks.2.att.receptance.weight\n8     1024  blocks.2.att.receptance.lora_A\n1024  8     blocks.2.att.receptance.lora_B\n1024  1024  blocks.2.att.output.weight\n1024        blocks.2.ffn.time_mix_k\n1024        blocks.2.ffn.time_mix_r\n4096  1024  blocks.2.ffn.key.weight\n8     1024  blocks.2.ffn.key.lora_A\n4096  8     blocks.2.ffn.key.lora_B\n1024  1024  blocks.2.ffn.receptance.weight\n8     1024  blocks.2.ffn.receptance.lora_A\n1024  8     blocks.2.ffn.receptance.lora_B\n1024  4096  blocks.2.ffn.value.weight\n8     4096  blocks.2.ffn.value.lora_A\n1024  8     blocks.2.ffn.value.lora_B\n1024        blocks.3.ln1.weight\n1024        blocks.3.ln1.bias\n1024        blocks.3.ln2.weight\n1024        blocks.3.ln2.bias\n1024        blocks.3.att.time_decay\n1024        blocks.3.att.time_first\n1024        blocks.3.att.time_mix_k\n1024        blocks.3.att.time_mix_v\n1024        blocks.3.att.time_mix_r\n1024  1024  blocks.3.att.key.weight\n8     1024  blocks.3.att.key.lora_A\n1024  8     blocks.3.att.key.lora_B\n1024  1024  blocks.3.att.value.weight\n8     1024  blocks.3.att.value.lora_A\n1024  8     blocks.3.att.value.lora_B\n1024  1024  blocks.3.att.receptance.weight\n8     1024  blocks.3.att.receptance.lora_A\n1024  8     blocks.3.att.receptance.lora_B\n1024  1024  blocks.3.att.output.weight\n1024        blocks.3.ffn.time_mix_k\n1024        blocks.3.ffn.time_mix_r\n4096  1024  blocks.3.ffn.key.weight\n8     1024  blocks.3.ffn.key.lora_A\n4096  8     blocks.3.ffn.key.lora_B\n1024  1024  blocks.3.ffn.receptance.weight\n8     1024  blocks.3.ffn.receptance.lora_A\n1024  8     blocks.3.ffn.receptance.lora_B\n1024  4096  blocks.3.ffn.value.weight\n8     4096  blocks.3.ffn.value.lora_A\n1024  8     blocks.3.ffn.value.lora_B\n1024        blocks.4.ln1.weight\n1024        blocks.4.ln1.bias\n1024        blocks.4.ln2.weight\n1024        blocks.4.ln2.bias\n1024        blocks.4.att.time_decay\n1024        blocks.4.att.time_first\n1024        blocks.4.att.time_mix_k\n1024        blocks.4.att.time_mix_v\n1024        blocks.4.att.time_mix_r\n1024  1024  blocks.4.att.key.weight\n8     1024  blocks.4.att.key.lora_A\n1024  8     blocks.4.att.key.lora_B\n1024  1024  blocks.4.att.value.weight\n8     1024  blocks.4.att.value.lora_A\n1024  8     blocks.4.att.value.lora_B\n1024  1024  blocks.4.att.receptance.weight\n8     1024  blocks.4.att.receptance.lora_A\n1024  8     blocks.4.att.receptance.lora_B\n1024  1024  blocks.4.att.output.weight\n1024        blocks.4.ffn.time_mix_k\n1024        blocks.4.ffn.time_mix_r\n4096  1024  blocks.4.ffn.key.weight\n8     1024  blocks.4.ffn.key.lora_A\n4096  8     blocks.4.ffn.key.lora_B\n1024  1024  blocks.4.ffn.receptance.weight\n8     1024  blocks.4.ffn.receptance.lora_A\n1024  8     blocks.4.ffn.receptance.lora_B\n1024  4096  blocks.4.ffn.value.weight\n8     4096  blocks.4.ffn.value.lora_A\n1024  8     blocks.4.ffn.value.lora_B\n1024        blocks.5.ln1.weight\n1024        blocks.5.ln1.bias\n1024        blocks.5.ln2.weight\n1024        blocks.5.ln2.bias\n1024        blocks.5.att.time_decay\n1024        blocks.5.att.time_first\n1024        blocks.5.att.time_mix_k\n1024        blocks.5.att.time_mix_v\n1024        blocks.5.att.time_mix_r\n1024  1024  blocks.5.att.key.weight\n8     1024  blocks.5.att.key.lora_A\n1024  8     blocks.5.att.key.lora_B\n1024  1024  blocks.5.att.value.weight\n8     1024  blocks.5.att.value.lora_A\n1024  8     blocks.5.att.value.lora_B\n1024  1024  blocks.5.att.receptance.weight\n8     1024  blocks.5.att.receptance.lora_A\n1024  8     blocks.5.att.receptance.lora_B\n1024  1024  blocks.5.att.output.weight\n1024        blocks.5.ffn.time_mix_k\n1024        blocks.5.ffn.time_mix_r\n4096  1024  blocks.5.ffn.key.weight\n8     1024  blocks.5.ffn.key.lora_A\n4096  8     blocks.5.ffn.key.lora_B\n1024  1024  blocks.5.ffn.receptance.weight\n8     1024  blocks.5.ffn.receptance.lora_A\n1024  8     blocks.5.ffn.receptance.lora_B\n1024  4096  blocks.5.ffn.value.weight\n8     4096  blocks.5.ffn.value.lora_A\n1024  8     blocks.5.ffn.value.lora_B\n1024        blocks.6.ln1.weight\n1024        blocks.6.ln1.bias\n1024        blocks.6.ln2.weight\n1024        blocks.6.ln2.bias\n1024        blocks.6.att.time_decay\n1024        blocks.6.att.time_first\n1024        blocks.6.att.time_mix_k\n1024        blocks.6.att.time_mix_v\n1024        blocks.6.att.time_mix_r\n1024  1024  blocks.6.att.key.weight\n8     1024  blocks.6.att.key.lora_A\n1024  8     blocks.6.att.key.lora_B\n1024  1024  blocks.6.att.value.weight\n8     1024  blocks.6.att.value.lora_A\n1024  8     blocks.6.att.value.lora_B\n1024  1024  blocks.6.att.receptance.weight\n8     1024  blocks.6.att.receptance.lora_A\n1024  8     blocks.6.att.receptance.lora_B\n1024  1024  blocks.6.att.output.weight\n1024        blocks.6.ffn.time_mix_k\n1024        blocks.6.ffn.time_mix_r\n4096  1024  blocks.6.ffn.key.weight\n8     1024  blocks.6.ffn.key.lora_A\n4096  8     blocks.6.ffn.key.lora_B\n1024  1024  blocks.6.ffn.receptance.weight\n8     1024  blocks.6.ffn.receptance.lora_A\n1024  8     blocks.6.ffn.receptance.lora_B\n1024  4096  blocks.6.ffn.value.weight\n8     4096  blocks.6.ffn.value.lora_A\n1024  8     blocks.6.ffn.value.lora_B\n1024        blocks.7.ln1.weight\n1024        blocks.7.ln1.bias\n1024        blocks.7.ln2.weight\n1024        blocks.7.ln2.bias\n1024        blocks.7.att.time_decay\n1024        blocks.7.att.time_first\n1024        blocks.7.att.time_mix_k\n1024        blocks.7.att.time_mix_v\n1024        blocks.7.att.time_mix_r\n1024  1024  blocks.7.att.key.weight\n8     1024  blocks.7.att.key.lora_A\n1024  8     blocks.7.att.key.lora_B\n1024  1024  blocks.7.att.value.weight\n8     1024  blocks.7.att.value.lora_A\n1024  8     blocks.7.att.value.lora_B\n1024  1024  blocks.7.att.receptance.weight\n8     1024  blocks.7.att.receptance.lora_A\n1024  8     blocks.7.att.receptance.lora_B\n1024  1024  blocks.7.att.output.weight\n1024        blocks.7.ffn.time_mix_k\n1024        blocks.7.ffn.time_mix_r\n4096  1024  blocks.7.ffn.key.weight\n8     1024  blocks.7.ffn.key.lora_A\n4096  8     blocks.7.ffn.key.lora_B\n1024  1024  blocks.7.ffn.receptance.weight\n8     1024  blocks.7.ffn.receptance.lora_A\n1024  8     blocks.7.ffn.receptance.lora_B\n1024  4096  blocks.7.ffn.value.weight\n8     4096  blocks.7.ffn.value.lora_A\n1024  8     blocks.7.ffn.value.lora_B\n1024        blocks.8.ln1.weight\n1024        blocks.8.ln1.bias\n1024        blocks.8.ln2.weight\n1024        blocks.8.ln2.bias\n1024        blocks.8.att.time_decay\n1024        blocks.8.att.time_first\n1024        blocks.8.att.time_mix_k\n1024        blocks.8.att.time_mix_v\n1024        blocks.8.att.time_mix_r\n1024  1024  blocks.8.att.key.weight\n8     1024  blocks.8.att.key.lora_A\n1024  8     blocks.8.att.key.lora_B\n1024  1024  blocks.8.att.value.weight\n8     1024  blocks.8.att.value.lora_A\n1024  8     blocks.8.att.value.lora_B\n1024  1024  blocks.8.att.receptance.weight\n8     1024  blocks.8.att.receptance.lora_A\n1024  8     blocks.8.att.receptance.lora_B\n1024  1024  blocks.8.att.output.weight\n1024        blocks.8.ffn.time_mix_k\n1024        blocks.8.ffn.time_mix_r\n4096  1024  blocks.8.ffn.key.weight\n8     1024  blocks.8.ffn.key.lora_A\n4096  8     blocks.8.ffn.key.lora_B\n1024  1024  blocks.8.ffn.receptance.weight\n8     1024  blocks.8.ffn.receptance.lora_A\n1024  8     blocks.8.ffn.receptance.lora_B\n1024  4096  blocks.8.ffn.value.weight\n8     4096  blocks.8.ffn.value.lora_A\n1024  8     blocks.8.ffn.value.lora_B\n1024        blocks.9.ln1.weight\n1024        blocks.9.ln1.bias\n1024        blocks.9.ln2.weight\n1024        blocks.9.ln2.bias\n1024        blocks.9.att.time_decay\n1024        blocks.9.att.time_first\n1024        blocks.9.att.time_mix_k\n1024        blocks.9.att.time_mix_v\n1024        blocks.9.att.time_mix_r\n1024  1024  blocks.9.att.key.weight\n8     1024  blocks.9.att.key.lora_A\n1024  8     blocks.9.att.key.lora_B\n1024  1024  blocks.9.att.value.weight\n8     1024  blocks.9.att.value.lora_A\n1024  8     blocks.9.att.value.lora_B\n1024  1024  blocks.9.att.receptance.weight\n8     1024  blocks.9.att.receptance.lora_A\n1024  8     blocks.9.att.receptance.lora_B\n1024  1024  blocks.9.att.output.weight\n1024        blocks.9.ffn.time_mix_k\n1024        blocks.9.ffn.time_mix_r\n4096  1024  blocks.9.ffn.key.weight\n8     1024  blocks.9.ffn.key.lora_A\n4096  8     blocks.9.ffn.key.lora_B\n1024  1024  blocks.9.ffn.receptance.weight\n8     1024  blocks.9.ffn.receptance.lora_A\n1024  8     blocks.9.ffn.receptance.lora_B\n1024  4096  blocks.9.ffn.value.weight\n8     4096  blocks.9.ffn.value.lora_A\n1024  8     blocks.9.ffn.value.lora_B\n1024        blocks.10.ln1.weight\n1024        blocks.10.ln1.bias\n1024        blocks.10.ln2.weight\n1024        blocks.10.ln2.bias\n1024        blocks.10.att.time_decay\n1024        blocks.10.att.time_first\n1024        blocks.10.att.time_mix_k\n1024        blocks.10.att.time_mix_v\n1024        blocks.10.att.time_mix_r\n1024  1024  blocks.10.att.key.weight\n8     1024  blocks.10.att.key.lora_A\n1024  8     blocks.10.att.key.lora_B\n1024  1024  blocks.10.att.value.weight\n8     1024  blocks.10.att.value.lora_A\n1024  8     blocks.10.att.value.lora_B\n1024  1024  blocks.10.att.receptance.weight\n8     1024  blocks.10.att.receptance.lora_A\n1024  8     blocks.10.att.receptance.lora_B\n1024  1024  blocks.10.att.output.weight\n1024        blocks.10.ffn.time_mix_k\n1024        blocks.10.ffn.time_mix_r\n4096  1024  blocks.10.ffn.key.weight\n8     1024  blocks.10.ffn.key.lora_A\n4096  8     blocks.10.ffn.key.lora_B\n1024  1024  blocks.10.ffn.receptance.weight\n8     1024  blocks.10.ffn.receptance.lora_A\n1024  8     blocks.10.ffn.receptance.lora_B\n1024  4096  blocks.10.ffn.value.weight\n8     4096  blocks.10.ffn.value.lora_A\n1024  8     blocks.10.ffn.value.lora_B\n1024        blocks.11.ln1.weight\n1024        blocks.11.ln1.bias\n1024        blocks.11.ln2.weight\n1024        blocks.11.ln2.bias\n1024        blocks.11.att.time_decay\n1024        blocks.11.att.time_first\n1024        blocks.11.att.time_mix_k\n1024        blocks.11.att.time_mix_v\n1024        blocks.11.att.time_mix_r\n1024  1024  blocks.11.att.key.weight\n8     1024  blocks.11.att.key.lora_A\n1024  8     blocks.11.att.key.lora_B\n1024  1024  blocks.11.att.value.weight\n8     1024  blocks.11.att.value.lora_A\n1024  8     blocks.11.att.value.lora_B\n1024  1024  blocks.11.att.receptance.weight\n8     1024  blocks.11.att.receptance.lora_A\n1024  8     blocks.11.att.receptance.lora_B\n1024  1024  blocks.11.att.output.weight\n1024        blocks.11.ffn.time_mix_k\n1024        blocks.11.ffn.time_mix_r\n4096  1024  blocks.11.ffn.key.weight\n8     1024  blocks.11.ffn.key.lora_A\n4096  8     blocks.11.ffn.key.lora_B\n1024  1024  blocks.11.ffn.receptance.weight\n8     1024  blocks.11.ffn.receptance.lora_A\n1024  8     blocks.11.ffn.receptance.lora_B\n1024  4096  blocks.11.ffn.value.weight\n8     4096  blocks.11.ffn.value.lora_A\n1024  8     blocks.11.ffn.value.lora_B\n1024        blocks.12.ln1.weight\n1024        blocks.12.ln1.bias\n1024        blocks.12.ln2.weight\n1024        blocks.12.ln2.bias\n1024        blocks.12.att.time_decay\n1024        blocks.12.att.time_first\n1024        blocks.12.att.time_mix_k\n1024        blocks.12.att.time_mix_v\n1024        blocks.12.att.time_mix_r\n1024  1024  blocks.12.att.key.weight\n8     1024  blocks.12.att.key.lora_A\n1024  8     blocks.12.att.key.lora_B\n1024  1024  blocks.12.att.value.weight\n8     1024  blocks.12.att.value.lora_A\n1024  8     blocks.12.att.value.lora_B\n1024  1024  blocks.12.att.receptance.weight\n8     1024  blocks.12.att.receptance.lora_A\n1024  8     blocks.12.att.receptance.lora_B\n1024  1024  blocks.12.att.output.weight\n1024        blocks.12.ffn.time_mix_k\n1024        blocks.12.ffn.time_mix_r\n4096  1024  blocks.12.ffn.key.weight\n8     1024  blocks.12.ffn.key.lora_A\n4096  8     blocks.12.ffn.key.lora_B\n1024  1024  blocks.12.ffn.receptance.weight\n8     1024  blocks.12.ffn.receptance.lora_A\n1024  8     blocks.12.ffn.receptance.lora_B\n1024  4096  blocks.12.ffn.value.weight\n8     4096  blocks.12.ffn.value.lora_A\n1024  8     blocks.12.ffn.value.lora_B\n1024        blocks.13.ln1.weight\n1024        blocks.13.ln1.bias\n1024        blocks.13.ln2.weight\n1024        blocks.13.ln2.bias\n1024        blocks.13.att.time_decay\n1024        blocks.13.att.time_first\n1024        blocks.13.att.time_mix_k\n1024        blocks.13.att.time_mix_v\n1024        blocks.13.att.time_mix_r\n1024  1024  blocks.13.att.key.weight\n8     1024  blocks.13.att.key.lora_A\n1024  8     blocks.13.att.key.lora_B\n1024  1024  blocks.13.att.value.weight\n8     1024  blocks.13.att.value.lora_A\n1024  8     blocks.13.att.value.lora_B\n1024  1024  blocks.13.att.receptance.weight\n8     1024  blocks.13.att.receptance.lora_A\n1024  8     blocks.13.att.receptance.lora_B\n1024  1024  blocks.13.att.output.weight\n1024        blocks.13.ffn.time_mix_k\n1024        blocks.13.ffn.time_mix_r\n4096  1024  blocks.13.ffn.key.weight\n8     1024  blocks.13.ffn.key.lora_A\n4096  8     blocks.13.ffn.key.lora_B\n1024  1024  blocks.13.ffn.receptance.weight\n8     1024  blocks.13.ffn.receptance.lora_A\n1024  8     blocks.13.ffn.receptance.lora_B\n1024  4096  blocks.13.ffn.value.weight\n8     4096  blocks.13.ffn.value.lora_A\n1024  8     blocks.13.ffn.value.lora_B\n1024        blocks.14.ln1.weight\n1024        blocks.14.ln1.bias\n1024        blocks.14.ln2.weight\n1024        blocks.14.ln2.bias\n1024        blocks.14.att.time_decay\n1024        blocks.14.att.time_first\n1024        blocks.14.att.time_mix_k\n1024        blocks.14.att.time_mix_v\n1024        blocks.14.att.time_mix_r\n1024  1024  blocks.14.att.key.weight\n8     1024  blocks.14.att.key.lora_A\n1024  8     blocks.14.att.key.lora_B\n1024  1024  blocks.14.att.value.weight\n8     1024  blocks.14.att.value.lora_A\n1024  8     blocks.14.att.value.lora_B\n1024  1024  blocks.14.att.receptance.weight\n8     1024  blocks.14.att.receptance.lora_A\n1024  8     blocks.14.att.receptance.lora_B\n1024  1024  blocks.14.att.output.weight\n1024        blocks.14.ffn.time_mix_k\n1024        blocks.14.ffn.time_mix_r\n4096  1024  blocks.14.ffn.key.weight\n8     1024  blocks.14.ffn.key.lora_A\n4096  8     blocks.14.ffn.key.lora_B\n1024  1024  blocks.14.ffn.receptance.weight\n8     1024  blocks.14.ffn.receptance.lora_A\n1024  8     blocks.14.ffn.receptance.lora_B\n1024  4096  blocks.14.ffn.value.weight\n8     4096  blocks.14.ffn.value.lora_A\n1024  8     blocks.14.ffn.value.lora_B\n1024        blocks.15.ln1.weight\n1024        blocks.15.ln1.bias\n1024        blocks.15.ln2.weight\n1024        blocks.15.ln2.bias\n1024        blocks.15.att.time_decay\n1024        blocks.15.att.time_first\n1024        blocks.15.att.time_mix_k\n1024        blocks.15.att.time_mix_v\n1024        blocks.15.att.time_mix_r\n1024  1024  blocks.15.att.key.weight\n8     1024  blocks.15.att.key.lora_A\n1024  8     blocks.15.att.key.lora_B\n1024  1024  blocks.15.att.value.weight\n8     1024  blocks.15.att.value.lora_A\n1024  8     blocks.15.att.value.lora_B\n1024  1024  blocks.15.att.receptance.weight\n8     1024  blocks.15.att.receptance.lora_A\n1024  8     blocks.15.att.receptance.lora_B\n1024  1024  blocks.15.att.output.weight\n1024        blocks.15.ffn.time_mix_k\n1024        blocks.15.ffn.time_mix_r\n4096  1024  blocks.15.ffn.key.weight\n8     1024  blocks.15.ffn.key.lora_A\n4096  8     blocks.15.ffn.key.lora_B\n1024  1024  blocks.15.ffn.receptance.weight\n8     1024  blocks.15.ffn.receptance.lora_A\n1024  8     blocks.15.ffn.receptance.lora_B\n1024  4096  blocks.15.ffn.value.weight\n8     4096  blocks.15.ffn.value.lora_A\n1024  8     blocks.15.ffn.value.lora_B\n1024        blocks.16.ln1.weight\n1024        blocks.16.ln1.bias\n1024        blocks.16.ln2.weight\n1024        blocks.16.ln2.bias\n1024        blocks.16.att.time_decay\n1024        blocks.16.att.time_first\n1024        blocks.16.att.time_mix_k\n1024        blocks.16.att.time_mix_v\n1024        blocks.16.att.time_mix_r\n1024  1024  blocks.16.att.key.weight\n8     1024  blocks.16.att.key.lora_A\n1024  8     blocks.16.att.key.lora_B\n1024  1024  blocks.16.att.value.weight\n8     1024  blocks.16.att.value.lora_A\n1024  8     blocks.16.att.value.lora_B\n1024  1024  blocks.16.att.receptance.weight\n8     1024  blocks.16.att.receptance.lora_A\n1024  8     blocks.16.att.receptance.lora_B\n1024  1024  blocks.16.att.output.weight\n1024        blocks.16.ffn.time_mix_k\n1024        blocks.16.ffn.time_mix_r\n4096  1024  blocks.16.ffn.key.weight\n8     1024  blocks.16.ffn.key.lora_A\n4096  8     blocks.16.ffn.key.lora_B\n1024  1024  blocks.16.ffn.receptance.weight\n8     1024  blocks.16.ffn.receptance.lora_A\n1024  8     blocks.16.ffn.receptance.lora_B\n1024  4096  blocks.16.ffn.value.weight\n8     4096  blocks.16.ffn.value.lora_A\n1024  8     blocks.16.ffn.value.lora_B\n1024        blocks.17.ln1.weight\n1024        blocks.17.ln1.bias\n1024        blocks.17.ln2.weight\n1024        blocks.17.ln2.bias\n1024        blocks.17.att.time_decay\n1024        blocks.17.att.time_first\n1024        blocks.17.att.time_mix_k\n1024        blocks.17.att.time_mix_v\n1024        blocks.17.att.time_mix_r\n1024  1024  blocks.17.att.key.weight\n8     1024  blocks.17.att.key.lora_A\n1024  8     blocks.17.att.key.lora_B\n1024  1024  blocks.17.att.value.weight\n8     1024  blocks.17.att.value.lora_A\n1024  8     blocks.17.att.value.lora_B\n1024  1024  blocks.17.att.receptance.weight\n8     1024  blocks.17.att.receptance.lora_A\n1024  8     blocks.17.att.receptance.lora_B\n1024  1024  blocks.17.att.output.weight\n1024        blocks.17.ffn.time_mix_k\n1024        blocks.17.ffn.time_mix_r\n4096  1024  blocks.17.ffn.key.weight\n8     1024  blocks.17.ffn.key.lora_A\n4096  8     blocks.17.ffn.key.lora_B\n1024  1024  blocks.17.ffn.receptance.weight\n8     1024  blocks.17.ffn.receptance.lora_A\n1024  8     blocks.17.ffn.receptance.lora_B\n1024  4096  blocks.17.ffn.value.weight\n8     4096  blocks.17.ffn.value.lora_A\n1024  8     blocks.17.ffn.value.lora_B\n1024        blocks.18.ln1.weight\n1024        blocks.18.ln1.bias\n1024        blocks.18.ln2.weight\n1024        blocks.18.ln2.bias\n1024        blocks.18.att.time_decay\n1024        blocks.18.att.time_first\n1024        blocks.18.att.time_mix_k\n1024        blocks.18.att.time_mix_v\n1024        blocks.18.att.time_mix_r\n1024  1024  blocks.18.att.key.weight\n8     1024  blocks.18.att.key.lora_A\n1024  8     blocks.18.att.key.lora_B\n1024  1024  blocks.18.att.value.weight\n8     1024  blocks.18.att.value.lora_A\n1024  8     blocks.18.att.value.lora_B\n1024  1024  blocks.18.att.receptance.weight\n8     1024  blocks.18.att.receptance.lora_A\n1024  8     blocks.18.att.receptance.lora_B\n1024  1024  blocks.18.att.output.weight\n1024        blocks.18.ffn.time_mix_k\n1024        blocks.18.ffn.time_mix_r\n4096  1024  blocks.18.ffn.key.weight\n8     1024  blocks.18.ffn.key.lora_A\n4096  8     blocks.18.ffn.key.lora_B\n1024  1024  blocks.18.ffn.receptance.weight\n8     1024  blocks.18.ffn.receptance.lora_A\n1024  8     blocks.18.ffn.receptance.lora_B\n1024  4096  blocks.18.ffn.value.weight\n8     4096  blocks.18.ffn.value.lora_A\n1024  8     blocks.18.ffn.value.lora_B\n1024        blocks.19.ln1.weight\n1024        blocks.19.ln1.bias\n1024        blocks.19.ln2.weight\n1024        blocks.19.ln2.bias\n1024        blocks.19.att.time_decay\n1024        blocks.19.att.time_first\n1024        blocks.19.att.time_mix_k\n1024        blocks.19.att.time_mix_v\n1024        blocks.19.att.time_mix_r\n1024  1024  blocks.19.att.key.weight\n8     1024  blocks.19.att.key.lora_A\n1024  8     blocks.19.att.key.lora_B\n1024  1024  blocks.19.att.value.weight\n8     1024  blocks.19.att.value.lora_A\n1024  8     blocks.19.att.value.lora_B\n1024  1024  blocks.19.att.receptance.weight\n8     1024  blocks.19.att.receptance.lora_A\n1024  8     blocks.19.att.receptance.lora_B\n1024  1024  blocks.19.att.output.weight\n1024        blocks.19.ffn.time_mix_k\n1024        blocks.19.ffn.time_mix_r\n4096  1024  blocks.19.ffn.key.weight\n8     1024  blocks.19.ffn.key.lora_A\n4096  8     blocks.19.ffn.key.lora_B\n1024  1024  blocks.19.ffn.receptance.weight\n8     1024  blocks.19.ffn.receptance.lora_A\n1024  8     blocks.19.ffn.receptance.lora_B\n1024  4096  blocks.19.ffn.value.weight\n8     4096  blocks.19.ffn.value.lora_A\n1024  8     blocks.19.ffn.value.lora_B\n1024        blocks.20.ln1.weight\n1024        blocks.20.ln1.bias\n1024        blocks.20.ln2.weight\n1024        blocks.20.ln2.bias\n1024        blocks.20.att.time_decay\n1024        blocks.20.att.time_first\n1024        blocks.20.att.time_mix_k\n1024        blocks.20.att.time_mix_v\n1024        blocks.20.att.time_mix_r\n1024  1024  blocks.20.att.key.weight\n8     1024  blocks.20.att.key.lora_A\n1024  8     blocks.20.att.key.lora_B\n1024  1024  blocks.20.att.value.weight\n8     1024  blocks.20.att.value.lora_A\n1024  8     blocks.20.att.value.lora_B\n1024  1024  blocks.20.att.receptance.weight\n8     1024  blocks.20.att.receptance.lora_A\n1024  8     blocks.20.att.receptance.lora_B\n1024  1024  blocks.20.att.output.weight\n1024        blocks.20.ffn.time_mix_k\n1024        blocks.20.ffn.time_mix_r\n4096  1024  blocks.20.ffn.key.weight\n8     1024  blocks.20.ffn.key.lora_A\n4096  8     blocks.20.ffn.key.lora_B\n1024  1024  blocks.20.ffn.receptance.weight\n8     1024  blocks.20.ffn.receptance.lora_A\n1024  8     blocks.20.ffn.receptance.lora_B\n1024  4096  blocks.20.ffn.value.weight\n8     4096  blocks.20.ffn.value.lora_A\n1024  8     blocks.20.ffn.value.lora_B\n1024        blocks.21.ln1.weight\n1024        blocks.21.ln1.bias\n1024        blocks.21.ln2.weight\n1024        blocks.21.ln2.bias\n1024        blocks.21.att.time_decay\n1024        blocks.21.att.time_first\n1024        blocks.21.att.time_mix_k\n1024        blocks.21.att.time_mix_v\n1024        blocks.21.att.time_mix_r\n1024  1024  blocks.21.att.key.weight\n8     1024  blocks.21.att.key.lora_A\n1024  8     blocks.21.att.key.lora_B\n1024  1024  blocks.21.att.value.weight\n8     1024  blocks.21.att.value.lora_A\n1024  8     blocks.21.att.value.lora_B\n1024  1024  blocks.21.att.receptance.weight\n8     1024  blocks.21.att.receptance.lora_A\n1024  8     blocks.21.att.receptance.lora_B\n1024  1024  blocks.21.att.output.weight\n1024        blocks.21.ffn.time_mix_k\n1024        blocks.21.ffn.time_mix_r\n4096  1024  blocks.21.ffn.key.weight\n8     1024  blocks.21.ffn.key.lora_A\n4096  8     blocks.21.ffn.key.lora_B\n1024  1024  blocks.21.ffn.receptance.weight\n8     1024  blocks.21.ffn.receptance.lora_A\n1024  8     blocks.21.ffn.receptance.lora_B\n1024  4096  blocks.21.ffn.value.weight\n8     4096  blocks.21.ffn.value.lora_A\n1024  8     blocks.21.ffn.value.lora_B\n1024        blocks.22.ln1.weight\n1024        blocks.22.ln1.bias\n1024        blocks.22.ln2.weight\n1024        blocks.22.ln2.bias\n1024        blocks.22.att.time_decay\n1024        blocks.22.att.time_first\n1024        blocks.22.att.time_mix_k\n1024        blocks.22.att.time_mix_v\n1024        blocks.22.att.time_mix_r\n1024  1024  blocks.22.att.key.weight\n8     1024  blocks.22.att.key.lora_A\n1024  8     blocks.22.att.key.lora_B\n1024  1024  blocks.22.att.value.weight\n8     1024  blocks.22.att.value.lora_A\n1024  8     blocks.22.att.value.lora_B\n1024  1024  blocks.22.att.receptance.weight\n8     1024  blocks.22.att.receptance.lora_A\n1024  8     blocks.22.att.receptance.lora_B\n1024  1024  blocks.22.att.output.weight\n1024        blocks.22.ffn.time_mix_k\n1024        blocks.22.ffn.time_mix_r\n4096  1024  blocks.22.ffn.key.weight\n8     1024  blocks.22.ffn.key.lora_A\n4096  8     blocks.22.ffn.key.lora_B\n1024  1024  blocks.22.ffn.receptance.weight\n8     1024  blocks.22.ffn.receptance.lora_A\n1024  8     blocks.22.ffn.receptance.lora_B\n1024  4096  blocks.22.ffn.value.weight\n8     4096  blocks.22.ffn.value.lora_A\n1024  8     blocks.22.ffn.value.lora_B\n1024        blocks.23.ln1.weight\n1024        blocks.23.ln1.bias\n1024        blocks.23.ln2.weight\n1024        blocks.23.ln2.bias\n1024        blocks.23.att.time_decay\n1024        blocks.23.att.time_first\n1024        blocks.23.att.time_mix_k\n1024        blocks.23.att.time_mix_v\n1024        blocks.23.att.time_mix_r\n1024  1024  blocks.23.att.key.weight\n8     1024  blocks.23.att.key.lora_A\n1024  8     blocks.23.att.key.lora_B\n1024  1024  blocks.23.att.value.weight\n8     1024  blocks.23.att.value.lora_A\n1024  8     blocks.23.att.value.lora_B\n1024  1024  blocks.23.att.receptance.weight\n8     1024  blocks.23.att.receptance.lora_A\n1024  8     blocks.23.att.receptance.lora_B\n1024  1024  blocks.23.att.output.weight\n1024        blocks.23.ffn.time_mix_k\n1024        blocks.23.ffn.time_mix_r\n4096  1024  blocks.23.ffn.key.weight\n8     1024  blocks.23.ffn.key.lora_A\n4096  8     blocks.23.ffn.key.lora_B\n1024  1024  blocks.23.ffn.receptance.weight\n8     1024  blocks.23.ffn.receptance.lora_A\n1024  8     blocks.23.ffn.receptance.lora_B\n1024  4096  blocks.23.ffn.value.weight\n8     4096  blocks.23.ffn.value.lora_A\n1024  8     blocks.23.ffn.value.lora_B\n1024        ln_out.weight\n1024        ln_out.bias\n65536 1024  head.weight\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]}]}